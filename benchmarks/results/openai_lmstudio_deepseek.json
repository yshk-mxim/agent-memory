{
  "metadata": {
    "timestamp": "2026-02-01T00:17:07.571647+00:00",
    "server": "lmstudio",
    "base_url": "http://127.0.0.1:1234",
    "context_mode": "full",
    "api": "openai",
    "endpoint": "/v1/chat/completions",
    "machine": {
      "os": "Darwin",
      "os_version": "25.2.0",
      "chip": "arm64"
    },
    "git_sha": "d1035c5",
    "runs_per_scenario": 1,
    "quick": false
  },
  "experiments": {
    "1_cold_start": {
      "cold_short": {
        "runs": [
          {
            "scenario": "cold_short",
            "config": "lmstudio",
            "ttft_ms": 267.7412499906495,
            "e2e_ms": 749.8671670327894,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 7.652792334002221,
            "decode_tps": 130.67125780440782,
            "overall_tps": 130.67125780440782,
            "output_tokens": 63,
            "input_tokens": 0,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0,
            "raw_output": "The system's block-based KV (Key-Value) cache architecture is designed to efficiently manage memory usage by storing data in fixed-size blocks. Each block contains a specific number of token key-value pairs, which are used to store and retrieve data during the execution of a model. These blocks are allocated",
            "error": null
          }
        ],
        "stats": {
          "ttft_ms": {
            "mean": 267.7412499906495,
            "median": 267.7412499906495,
            "p95": 267.7412499906495,
            "p99": 267.7412499906495
          },
          "e2e_ms": {
            "mean": 749.8671670327894,
            "median": 749.8671670327894,
            "p95": 749.8671670327894,
            "p99": 749.8671670327894
          },
          "decode_tps": {
            "mean": 130.67125780440782,
            "median": 130.67125780440782,
            "p95": 130.67125780440782,
            "p99": 130.67125780440782
          },
          "peak_memory_mb": {
            "mean": 0.0,
            "median": 0,
            "p95": 0,
            "p99": 0
          }
        }
      },
      "cold_medium": {
        "runs": [
          {
            "scenario": "cold_medium",
            "config": "lmstudio",
            "ttft_ms": 1548.7709579756483,
            "e2e_ms": 2130.474832956679,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 9.233394840968744,
            "decode_tps": 108.30252764270207,
            "overall_tps": 108.30252764270207,
            "output_tokens": 63,
            "input_tokens": 0,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0,
            "raw_output": "a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors",
            "error": null
          }
        ],
        "stats": {
          "ttft_ms": {
            "mean": 1548.7709579756483,
            "median": 1548.7709579756483,
            "p95": 1548.7709579756483,
            "p99": 1548.7709579756483
          },
          "e2e_ms": {
            "mean": 2130.474832956679,
            "median": 2130.474832956679,
            "p95": 2130.474832956679,
            "p99": 2130.474832956679
          },
          "decode_tps": {
            "mean": 108.30252764270207,
            "median": 108.30252764270207,
            "p95": 108.30252764270207,
            "p99": 108.30252764270207
          },
          "peak_memory_mb": {
            "mean": 0.0,
            "median": 0,
            "p95": 0,
            "p99": 0
          }
        }
      },
      "cold_long": {
        "runs": [
          {
            "scenario": "cold_long",
            "config": "lmstudio",
            "ttft_ms": 0.0,
            "e2e_ms": 35.12995899654925,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 0,
            "decode_tps": 0,
            "overall_tps": 0,
            "output_tokens": 0,
            "input_tokens": 0,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0,
            "raw_output": "",
            "error": null
          }
        ],
        "stats": {
          "ttft_ms": {
            "mean": 0.0,
            "median": 0.0,
            "p95": 0.0,
            "p99": 0.0
          },
          "e2e_ms": {
            "mean": 35.12995899654925,
            "median": 35.12995899654925,
            "p95": 35.12995899654925,
            "p99": 35.12995899654925
          },
          "decode_tps": {
            "mean": 0.0,
            "median": 0,
            "p95": 0,
            "p99": 0
          },
          "peak_memory_mb": {
            "mean": 0.0,
            "median": 0,
            "p95": 0,
            "p99": 0
          }
        }
      },
      "cold_xl": {
        "runs": [
          {
            "scenario": "cold_xl",
            "config": "lmstudio",
            "ttft_ms": 0.0,
            "e2e_ms": 78.95529200322926,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 0,
            "decode_tps": 0,
            "overall_tps": 0,
            "output_tokens": 0,
            "input_tokens": 0,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0,
            "raw_output": "",
            "error": null
          }
        ],
        "stats": {
          "ttft_ms": {
            "mean": 0.0,
            "median": 0.0,
            "p95": 0.0,
            "p99": 0.0
          },
          "e2e_ms": {
            "mean": 78.95529200322926,
            "median": 78.95529200322926,
            "p95": 78.95529200322926,
            "p99": 78.95529200322926
          },
          "decode_tps": {
            "mean": 0.0,
            "median": 0,
            "p95": 0,
            "p99": 0
          },
          "peak_memory_mb": {
            "mean": 0.0,
            "median": 0,
            "p95": 0,
            "p99": 0
          }
        }
      }
    },
    "4_output_scaling": {
      "output_16": {
        "runs": [
          {
            "scenario": "output_16",
            "config": "lmstudio",
            "ttft_ms": 248.54887498077005,
            "e2e_ms": 248.54887498077005,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 16.569924998718005,
            "decode_tps": 60.35030334038137,
            "overall_tps": 60.35030334038137,
            "output_tokens": 15,
            "input_tokens": 729,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0.0,
            "raw_output": "implements a block-based KV cache architecture where each block stores a fixed number",
            "error": null
          }
        ],
        "stats": {
          "e2e_ms": {
            "mean": 248.54887498077005,
            "median": 248.54887498077005,
            "p95": 248.54887498077005,
            "p99": 248.54887498077005
          },
          "tpot_ms": {
            "mean": 16.569924998718005,
            "median": 16.569924998718005,
            "p95": 16.569924998718005,
            "p99": 16.569924998718005
          },
          "decode_tps": {
            "mean": 60.35030334038137,
            "median": 60.35030334038137,
            "p95": 60.35030334038137,
            "p99": 60.35030334038137
          }
        }
      },
      "output_64": {
        "runs": [
          {
            "scenario": "output_64",
            "config": "lmstudio",
            "ttft_ms": 639.8075000033714,
            "e2e_ms": 639.8075000033714,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 10.155674603228118,
            "decode_tps": 98.46711706203511,
            "overall_tps": 98.46711706203511,
            "output_tokens": 63,
            "input_tokens": 729,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0.0,
            "raw_output": "implements a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safet",
            "error": null
          }
        ],
        "stats": {
          "e2e_ms": {
            "mean": 639.8075000033714,
            "median": 639.8075000033714,
            "p95": 639.8075000033714,
            "p99": 639.8075000033714
          },
          "tpot_ms": {
            "mean": 10.155674603228118,
            "median": 10.155674603228118,
            "p95": 10.155674603228118,
            "p99": 10.155674603228118
          },
          "decode_tps": {
            "mean": 98.46711706203511,
            "median": 98.46711706203511,
            "p95": 98.46711706203511,
            "p99": 98.46711706203511
          }
        }
      },
      "output_128": {
        "runs": [
          {
            "scenario": "output_128",
            "config": "lmstudio",
            "ttft_ms": 1235.3046659845859,
            "e2e_ms": 1235.3046659845859,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 9.726808393579416,
            "decode_tps": 102.80864591309226,
            "overall_tps": 102.80864591309226,
            "output_tokens": 127,
            "input_tokens": 729,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0.0,
            "raw_output": "implements a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors serialization. On subsequent requests, the cache is loaded from disk and reconstructed into quantized KV blocks. This design enables efficient memory management while preserving semantic context across conversations. The prefill phase processes input tokens in adaptive chunks to bound peak memory usage during long-context inference on Apple Silicon.\n\nIn this system, each",
            "error": null
          }
        ],
        "stats": {
          "e2e_ms": {
            "mean": 1235.3046659845859,
            "median": 1235.3046659845859,
            "p95": 1235.3046659845859,
            "p99": 1235.3046659845859
          },
          "tpot_ms": {
            "mean": 9.726808393579416,
            "median": 9.726808393579416,
            "p95": 9.726808393579416,
            "p99": 9.726808393579416
          },
          "decode_tps": {
            "mean": 102.80864591309226,
            "median": 102.80864591309226,
            "p95": 102.80864591309226,
            "p99": 102.80864591309226
          }
        }
      },
      "output_256": {
        "runs": [
          {
            "scenario": "output_256",
            "config": "lmstudio",
            "ttft_ms": 0.0,
            "e2e_ms": 2579.7271250048652,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 0.0,
            "decode_tps": 0.0,
            "overall_tps": 0.0,
            "output_tokens": 0,
            "input_tokens": 0,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0.0,
            "raw_output": "",
            "error": "HTTP 400: {\"error\":\"The model has crashed without additional information. (Exit code: null)\"}"
          }
        ],
        "stats": {
          "e2e_ms": {
            "mean": 0,
            "median": 0,
            "p95": 0,
            "p99": 0
          },
          "tpot_ms": {
            "mean": 0,
            "median": 0,
            "p95": 0,
            "p99": 0
          },
          "decode_tps": {
            "mean": 0,
            "median": 0,
            "p95": 0,
            "p99": 0
          }
        }
      },
      "output_512": {
        "runs": [
          {
            "scenario": "output_512",
            "config": "lmstudio",
            "ttft_ms": 10540.333374985494,
            "e2e_ms": 10540.333374985494,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 24.398919849503457,
            "decode_tps": 40.98542091896544,
            "overall_tps": 40.98542091896544,
            "output_tokens": 432,
            "input_tokens": 729,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0.0,
            "raw_output": "implements a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors serialization. On subsequent requests, the cache is loaded from disk and reconstructed into quantized KV blocks. This design enables efficient memory management while preserving semantic context across conversations. The prefill phase processes input tokens in adaptive chunks to bound peak memory usage during long-context inference on Apple Silicon.\n\nIn this system, each block has a fixed number of token key-value pairs, and these blocks are allocated from a shared pool. They are assigned per layer and per agent to ensure that each agent has its own cache space for storing data.\n\nWhen an agent's cache exceeds the capacity of the hot tier, which is the part of the memory that stores data most frequently accessed by the system, the least recently used agent is evicted to disk. This process involves serializing the data of this agent using a safetensors format, which is a specialized file format for storing tensors in a safe and efficient manner.\n\nWhen the system receives subsequent requests, it loads the cached data from disk and reconstructs it into quantized KV (key-value) blocks. This reconstruction process helps in efficiently managing memory usage and preserves the semantic context across different conversations, which is crucial for maintaining the coherence of information during extended dialogues.\n\nThe prefill phase in this system processes input tokens in adaptive chunks, which means that the size of these chunks is adjusted according to the available memory and the specific needs of the system during long-context inference tasks on Apple Silicon. This adaptive approach helps in controlling and minimizing peak memory usage during these computationally intensive processes, ensuring smooth operation of the system.\n\nOverall, this block-based KV cache architecture with safetensors serialization and adaptive chunking for prefill phase on Apple Silicon provides an efficient, memory-saving, and context-preserving solution for long-context inference tasks in conversational systems.",
            "error": null
          }
        ],
        "stats": {
          "e2e_ms": {
            "mean": 10540.333374985494,
            "median": 10540.333374985494,
            "p95": 10540.333374985494,
            "p99": 10540.333374985494
          },
          "tpot_ms": {
            "mean": 24.398919849503457,
            "median": 24.398919849503457,
            "p95": 24.398919849503457,
            "p99": 24.398919849503457
          },
          "decode_tps": {
            "mean": 40.98542091896544,
            "median": 40.98542091896544,
            "p95": 40.98542091896544,
            "p99": 40.98542091896544
          }
        }
      }
    },
    "5_concurrent": {
      "concurrent_r0": {
        "wall_ms": 2248.7505419994704,
        "system_tps": 56.03111489990679,
        "total_output_tokens": 126,
        "per_request": [
          {
            "scenario": "",
            "config": "",
            "ttft_ms": 1548.8913749577478,
            "e2e_ms": 1548.8913749577478,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 24.58557738028171,
            "decode_tps": 40.674253223030945,
            "overall_tps": 40.674253223030945,
            "output_tokens": 63,
            "input_tokens": 1450,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0.0,
            "raw_output": "a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors",
            "error": null
          },
          {
            "scenario": "",
            "config": "",
            "ttft_ms": 2248.4142500325106,
            "e2e_ms": 2248.4142500325106,
            "itl_mean_ms": 0.0,
            "itl_p95_ms": 0.0,
            "itl_p99_ms": 0.0,
            "tpot_ms": 35.68911507988112,
            "decode_tps": 28.01974769510959,
            "overall_tps": 28.01974769510959,
            "output_tokens": 63,
            "input_tokens": 1450,
            "cache_created": 0,
            "cache_read": 0,
            "memory_before_mb": 0.0,
            "memory_after_mb": 0.0,
            "peak_memory_mb": 0.0,
            "raw_output": "a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors",
            "error": null
          }
        ]
      },
      "stats": {
        "wall_ms": {
          "mean": 2248.7505419994704,
          "median": 2248.7505419994704,
          "p95": 2248.7505419994704,
          "p99": 2248.7505419994704
        },
        "system_tps": {
          "mean": 56.03111489990679,
          "median": 56.03111489990679,
          "p95": 56.03111489990679,
          "p99": 56.03111489990679
        }
      }
    }
  }
}