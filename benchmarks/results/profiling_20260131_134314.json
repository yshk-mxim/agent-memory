{
  "metadata": {
    "timestamp": "2026-01-31T21:43:14.909774+00:00",
    "model_id": "mlx-community/DeepSeek-Coder-V2-Lite-Instruct-4bit-mlx",
    "machine": {
      "os": "Darwin",
      "os_version": "25.2.0",
      "chip": "arm64"
    },
    "git_sha": "dea5835",
    "runs_per_scenario": 2,
    "quick": true
  },
  "experiments": {
    "E": {
      "E_output_scaling": {
        "description": "Output length scaling",
        "env": {
          "SEMANTIC_MLX_CHUNKED_PREFILL_ENABLED": "true",
          "SEMANTIC_MLX_CHUNKED_PREFILL_THRESHOLD": "2048",
          "SEMANTIC_MLX_CHUNKED_PREFILL_MIN_CHUNK": "512",
          "SEMANTIC_MLX_CHUNKED_PREFILL_MAX_CHUNK": "4096",
          "SEMANTIC_MLX_DEFAULT_TEMPERATURE": "0.0",
          "SEMANTIC_MLX_KV_BITS": "4",
          "SEMANTIC_MLX_MAX_CONTEXT_LENGTH": "100000",
          "SEMANTIC_MLX_MAX_BATCH_SIZE": "1",
          "SEMANTIC_MLX_SCHEDULER_ENABLED": "false",
          "SEMANTIC_MLX_PREFILL_STEP_SIZE": "256",
          "SEMANTIC_SERVER_LOG_LEVEL": "WARNING",
          "SEMANTIC_API_KEY": ""
        },
        "scenarios": {
          "output16": {
            "runs": [
              {
                "scenario": "output16",
                "config": "",
                "ttft_ms": 1219.3144169868901,
                "e2e_ms": 1219.9081250000745,
                "itl_mean_ms": 0.0,
                "itl_p95_ms": 0.0,
                "itl_p99_ms": 0.0,
                "tpot_ms": 76244.25781250466,
                "decode_tps": 26949.274129186124,
                "overall_tps": 26949.274129186124,
                "output_tokens": 16,
                "input_tokens": 728,
                "cache_created": 728,
                "cache_read": 0,
                "memory_before_mb": 8431.1,
                "memory_after_mb": 8487.2,
                "peak_memory_mb": 9082.6,
                "raw_output": " implements a block-based KV cache architecture where each block stores a fixed number of",
                "error": null
              },
              {
                "scenario": "output16",
                "config": "",
                "ttft_ms": 1048.1799579574727,
                "e2e_ms": 1048.870040976908,
                "itl_mean_ms": 0.0,
                "itl_p95_ms": 0.0,
                "itl_p99_ms": 0.0,
                "tpot_ms": 65554.37756105675,
                "decode_tps": 23185.61614961989,
                "overall_tps": 23185.61614961989,
                "output_tokens": 16,
                "input_tokens": 728,
                "cache_created": 728,
                "cache_read": 0,
                "memory_before_mb": 8431.1,
                "memory_after_mb": 8487.2,
                "peak_memory_mb": 9082.6,
                "raw_output": " implements a block-based KV cache architecture where each block stores a fixed number of",
                "error": null
              }
            ],
            "stats": {
              "ttft_ms": {
                "mean": 1133.7471874721814,
                "median": 1133.7471874721814,
                "p95": 1210.7576940354193,
                "p99": 1217.603072396596
              },
              "e2e_ms": {
                "mean": 1134.3890829884913,
                "median": 1134.3890829884913,
                "p95": 1211.3562207989162,
                "p99": 1218.1977441598428
              },
              "tpot_ms": {
                "mean": 70899.3176867807,
                "median": 70899.3176867807,
                "p95": 75709.76379993226,
                "p99": 76137.35900999018
              },
              "decode_tps": {
                "mean": 25067.445139403007,
                "median": 25067.445139403007,
                "p95": 26761.09123020781,
                "p99": 26911.63754939046
              },
              "overall_tps": {
                "mean": 25067.445139403007,
                "median": 25067.445139403007,
                "p95": 26761.09123020781,
                "p99": 26911.63754939046
              },
              "peak_memory_mb": {
                "mean": 9082.6,
                "median": 9082.6,
                "p95": 9082.6,
                "p99": 9082.6
              }
            }
          },
          "output64": {
            "runs": [
              {
                "scenario": "output64",
                "config": "",
                "ttft_ms": 1518.857792019844,
                "e2e_ms": 1521.2507499963976,
                "itl_mean_ms": 0.0,
                "itl_p95_ms": 0.0,
                "itl_p99_ms": 0.0,
                "tpot_ms": 23769.542968693713,
                "decode_tps": 26745.141631018003,
                "overall_tps": 26745.141631018003,
                "output_tokens": 64,
                "input_tokens": 728,
                "cache_created": 728,
                "cache_read": 0,
                "memory_before_mb": 8431.1,
                "memory_after_mb": 8491.4,
                "peak_memory_mb": 9082.6,
                "raw_output": " implements a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors",
                "error": null
              },
              {
                "scenario": "output64",
                "config": "",
                "ttft_ms": 1507.449583034031,
                "e2e_ms": 1508.0520410556346,
                "itl_mean_ms": 0.0,
                "itl_p95_ms": 0.0,
                "itl_p99_ms": 0.0,
                "tpot_ms": 23563.31314149429,
                "decode_tps": 106231.46792809766,
                "overall_tps": 106231.46792809766,
                "output_tokens": 64,
                "input_tokens": 728,
                "cache_created": 728,
                "cache_read": 0,
                "memory_before_mb": 8431.1,
                "memory_after_mb": 8491.4,
                "peak_memory_mb": 9082.6,
                "raw_output": " implements a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors",
                "error": null
              }
            ],
            "stats": {
              "ttft_ms": {
                "mean": 1513.1536875269376,
                "median": 1513.1536875269376,
                "p95": 1518.2873815705534,
                "p99": 1518.743709929986
              },
              "e2e_ms": {
                "mean": 1514.6513955260161,
                "median": 1514.6513955260161,
                "p95": 1520.5908145493595,
                "p99": 1521.11876290699
              },
              "tpot_ms": {
                "mean": 23666.428055094002,
                "median": 23666.428055094002,
                "p95": 23759.231477333742,
                "p99": 23767.48067042172
              },
              "decode_tps": {
                "mean": 66488.30477955783,
                "median": 66488.30477955783,
                "p95": 102257.15161324367,
                "p99": 105436.60466512687
              },
              "overall_tps": {
                "mean": 66488.30477955783,
                "median": 66488.30477955783,
                "p95": 102257.15161324367,
                "p99": 105436.60466512687
              },
              "peak_memory_mb": {
                "mean": 9082.6,
                "median": 9082.6,
                "p95": 9082.6,
                "p99": 9082.6
              }
            }
          },
          "output256": {
            "runs": [
              {
                "scenario": "output256",
                "config": "",
                "ttft_ms": 2062.952457985375,
                "e2e_ms": 2063.502666016575,
                "itl_mean_ms": 0.0,
                "itl_p95_ms": 0.0,
                "itl_p99_ms": 0.0,
                "tpot_ms": 17195.855550138123,
                "decode_tps": 218099.32461056343,
                "overall_tps": 218099.32461056343,
                "output_tokens": 120,
                "input_tokens": 728,
                "cache_created": 728,
                "cache_read": 0,
                "memory_before_mb": 8431.1,
                "memory_after_mb": 8495.2,
                "peak_memory_mb": 9082.6,
                "raw_output": " implements a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors serialization. On subsequent requests, the cache is loaded from disk and reconstructed into quantized KV blocks. This design enables efficient memory management while preserving semantic context across conversations. The prefill phase processes input tokens in adaptive chunks to bound peak memory usage during long-context inference on Apple Silicon.",
                "error": null
              },
              {
                "scenario": "output256",
                "config": "",
                "ttft_ms": 2086.5351670072414,
                "e2e_ms": 2087.1305000036955,
                "itl_mean_ms": 0.0,
                "itl_p95_ms": 0.0,
                "itl_p99_ms": 0.0,
                "tpot_ms": 17392.75416669746,
                "decode_tps": 201567.86322065388,
                "overall_tps": 201567.86322065388,
                "output_tokens": 120,
                "input_tokens": 728,
                "cache_created": 728,
                "cache_read": 0,
                "memory_before_mb": 8431.1,
                "memory_after_mb": 8495.2,
                "peak_memory_mb": 9082.6,
                "raw_output": " implements a block-based KV cache architecture where each block stores a fixed number of token key-value pairs. Blocks are allocated from a shared pool and assigned per-layer per-agent. When an agent's cache exceeds the hot tier capacity, the least recently used agent is evicted to disk via safetensors serialization. On subsequent requests, the cache is loaded from disk and reconstructed into quantized KV blocks. This design enables efficient memory management while preserving semantic context across conversations. The prefill phase processes input tokens in adaptive chunks to bound peak memory usage during long-context inference on Apple Silicon.",
                "error": null
              }
            ],
            "stats": {
              "ttft_ms": {
                "mean": 2074.7438124963082,
                "median": 2074.7438124963082,
                "p95": 2085.356031556148,
                "p99": 2086.2993399170227
              },
              "e2e_ms": {
                "mean": 2075.316583010135,
                "median": 2075.316583010135,
                "p95": 2085.9491083043395,
                "p99": 2086.8942216638243
              },
              "tpot_ms": {
                "mean": 17294.304858417792,
                "median": 17294.304858417792,
                "p95": 17382.909235869494,
                "p99": 17390.785180531868
              },
              "decode_tps": {
                "mean": 209833.59391560865,
                "median": 209833.59391560865,
                "p95": 217272.75154106796,
                "p99": 217934.00999666433
              },
              "overall_tps": {
                "mean": 209833.59391560865,
                "median": 209833.59391560865,
                "p95": 217272.75154106796,
                "p99": 217934.00999666433
              },
              "peak_memory_mb": {
                "mean": 9082.6,
                "median": 9082.6,
                "p95": 9082.6,
                "p99": 9082.6
              }
            }
          }
        }
      }
    }
  }
}