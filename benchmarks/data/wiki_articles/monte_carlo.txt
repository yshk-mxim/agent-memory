Monte Carlo methods, also called the Monte Carlo experiments or Monte Carlo simulations, are a broad class of computational algorithms based on repeated random sampling for obtaining numerical results. The underlying concept is to use randomness to solve deterministic problems. Monte Carlo methods are mainly used in three distinct problem classes: optimization, numerical integration, and non-uniform random variate generation, available for modeling phenomena with significant input uncertainties, e.g. risk assessments for nuclear power plants. Monte Carlo methods are often implemented using computer simulations. They can provide approximate solutions to problems too complex for mathematical analysis. == Overview == The name comes from the Monte Carlo Casino in Monaco, where the primary developer of the method, mathematician Stanisław Ulam, was inspired by his uncle's gambling habits. Monte Carlo methods are widely used in various fields of science, engineering, and mathematics, such as physics, chemistry, biology, statistics, artificial intelligence, finance, and cryptography. They have also been applied to social sciences, such as sociology, psychology, and political science. Monte Carlo methods have been recognized as one of the most important and influential ideas of the 20th century, and they have enabled many scientific and technological breakthroughs. Monte Carlo methods also have some limitations and challenges, such as the trade-off between accuracy and computational cost, the curse of dimensionality, the reliability of random number generators, and the verification and validation of the results. Monte Carlo methods vary, but tend to follow a particular pattern: Define a domain of possible inputs. Generate inputs randomly from a probability distribution over the domain. Perform a deterministic computation of the outputs. Aggregate the results. For example, consider a quadrant (circular sector) inscribed in a unit square. Given that the ratio of their areas is ⁠π/4⁠, the value of π can be approximated using the Monte Carlo method: Draw a square, then inscribe a quadrant within it. Uniformly scatter a given number of points over the square. Count the number of points inside the quadrant, i.e. having a distance from the origin of less than 1. The ratio of the inside-count and the total-sample-count is an estimate of the ratio of the two areas, ⁠π/4⁠. Multiply the result by 4 to estimate π. In this procedure, the domain of inputs is the square that circumscribes the quadrant. One can generate random inputs by scattering grains over the square, then performing a computation on each input to test whether it falls within the quadrant. Aggregating the results yields our final result, the approximation of π. There are two important considerations: If the points are not uniformly distributed, the approximation will be poor. The approximation improves as more points are randomly placed in the whole square. Uses of Monte Carlo methods require large amounts of random numbers, and their use benefitted greatly from pseudorandom number generators, which are far quicker to use than the tables of random numbers that had been previously employed. == Applications == Monte Carlo methods are often used in physical and mathematical problems and are most useful when it is difficult or impossible to use other approaches. Monte Carlo methods are mainly used in three problem classes: optimization, numerical integration, and generating draws from a probability distribution. In physics-related problems, Monte Carlo methods are useful for simulating systems with many coupled degrees of freedom, such as fluids, disordered materials, strongly coupled solids, and cellular structures, e.g. cellular Potts model, interacting particle systems, McKean–Vlasov processes, kinetic models of gases. Other examples include modeling phenomena with significant uncertainty in inputs such as the calculation of risk in business and, in mathematics, evaluation of multidimensional definite integrals with complicated boundary conditions. In application to systems engineering problems (space, oil exploration, aircraft design, etc.), Monte Carlo–based predictions of failure, cost overruns and schedule overruns are routinely better than human intuition or alternative "soft" methods. In principle, Monte Carlo methods can be used to solve any problem having a probabilistic interpretation. By the law of large numbers, integrals described by the expected value of some random variable can be approximated by taking the empirical mean (a.k.a. the 'sample mean') of independent samples of the variable. When the probability distribution of the variable is parameterized, mathematicians often use a Markov chain Monte Carlo (MCMC) sampler. The central idea is to design a judicious Markov chain model with a prescribed stationary probability distribution. That is, in the limit, the samples being generated by the MCMC method will be samples from the desired (target) distribution. By the ergodic theorem, the stationary distribution is approximated by the empirical measures of the random states of the MCMC sampler. In other problems, the objective is generating draws from a sequence of probability distributions satisfying a nonlinear evolution equation. These flows of probability distributions can always be interpreted as the distributions of the random states of a Markov process whose transition probabilities depend on the distributions of the current random states (see McKean–Vlasov processes, nonlinear filtering equation). In other instances, a flow of probability distributions with an increasing level of sampling complexity arise (path spaces models with an increasing time horizon, Boltzmann–Gibbs measures associated with decreasing temperature parameters, and many others). These models can also be seen as the evolution of the law of the random states of a nonlinear Markov chain. A natural way to simulate these sophisticated nonlinear Markov processes is to sample multiple copies of the process, replacing in the evolution equation the unknown distributions of the random states by the sampled empirical measures. In contrast with traditional Monte Carlo and MCMC methodologies, these mean-field particle techniques rely on sequential interacting samples. The terminology mean field reflects the fact that each of the samples (a.k.a. particles, individuals, walkers, agents, creatures, or phenotypes) interacts with the empirical measures of the process. When the size of the system tends to infinity, these random empirical measures converge to the deterministic distribution of the random states of the nonlinear Markov chain, so that the statistical interaction between particles vanishes. == Simple Monte Carlo == Suppose one wants to know the expected value μ {\displaystyle \mu } of a population (and knows that μ {\displaystyle \mu } exists), but does not have a formula available to compute it. The simple Monte Carlo method gives an estimate for μ {\displaystyle \mu } by running n {\displaystyle n} simulations and averaging the simulations' results. It has no restrictions on the probability distribution of the inputs to the simulations, requiring only that the inputs are randomly generated and are independent of each other and that μ {\displaystyle \mu } exists. A sufficiently large n {\displaystyle n} will produce a value for m {\displaystyle m} that is arbitrarily close to μ {\displaystyle \mu } ; more formally, it will be the case that, for any ϵ > 0 {\displaystyle \epsilon >0} , | μ − m | ≤ ϵ {\displaystyle |\mu -m|\leq \epsilon } . Typically, the algorithm to obtain m {\displaystyle m} is s = 0; for i = 1 to n do run the simulation for the ith time, giving result ri; s = s + ri; repeat m = s / n; === Examples === Suppose we want to know how many times we should expect to throw three eight-sided dice for the total of the dice throws to be at least T {\displaystyle T} . We know the expected value exists. The dice throws are randomly distributed and independent of each other. So simple Monte Carlo is applicable: s = 0; for i = 1 to n do throw the three dice until T is met or first exceeded; ri = the number of throws; s = s + ri; repeat m = s / n; If n {\displaystyle n} is large enough, m {\displaystyle m} will be within ϵ {\displaystyle \epsilon } of μ {\displaystyle \mu } for any ϵ > 0 {\displaystyle \epsilon >0} . === Determining a sufficiently large n === ==== General formula ==== Let ϵ = | μ − m | > 0 {\displaystyle \epsilon =|\mu -m|>0} . Choose the desired confidence level – the percent chance that, when the Monte Carlo algorithm completes, m {\displaystyle m} is indeed within ϵ {\displaystyle \epsilon } of μ {\displaystyle \mu } . Let z {\displaystyle z} be the z {\displaystyle z} -score corresponding to that confidence level. Let s 2 {\displaystyle s^{2}} be the estimated variance, sometimes called the "sample" variance; it is the variance of the results obtained from a relatively small number k {\displaystyle k} of "sample" simulations. Choose a k {\displaystyle k} ; Driels and Shin observe that "even for sample sizes an order of magnitude lower than the number required, the calculation of that number is quite stable." The following algorithm computes s 2 {\displaystyle s^{2}} in one pass while minimizing the possibility that accumulated numerical error produces erroneous results: s1 = 0; run the simulation for the first time, producing result r1; m1 = r1; //mi is the mean of the first i simulations for i = 2 to k do run the simulation for the ith time, producing result ri; δi = ri - mi−1; mi = mi-1 + (1/i)δi; si = si-1 + ((i - 1)/i)(δi)2; repeat s2 = sk/(k - 1); Note that, when the algorithm completes, m k {\displaystyle m_{k}} is the mean of the k {\displaystyle k} results. The value n {\displaystyle n} is sufficiently large when n ≥ s 2 z 2 / ϵ 2 . {\displaystyle n\geq s^{2}z^{2}/\epsilon ^{2}.} If n ≤ k {\displaystyle n\leq k} , then m k = m {\displaystyle m_{k}=m} ; sufficient sample simulations were done to ensure that m k {\displaystyle m_{k}} is within ϵ {\displaystyle \epsilon } of μ {\displaystyle \mu } . If n > k {\displaystyle n>k} , then n {\displaystyle n} simulations can be run "from scratch," or, since k {\displaystyle k} simulations have already been done, one can just run n − k {\displaystyle n-k} more simulations and add their results into those from the sample simulations: s = mk * k; for i = k + 1 to n do run the simulation for the ith time, giving result ri; s = s + ri; m = s / n; ==== Formulae for simulations' results with bounds ==== An alternative formula can be used in the special case where all simulation results are bounded above and below. Choose a value for ϵ {\displaystyle \epsilon } that is twice the maximum allowed difference between μ {\displaystyle \mu } and m {\displaystyle m} . Let 0 < δ < 100 {\displaystyle 0<\delta <100} be the desired confidence level, expressed as a percentage. Let every simulation result r 1 , r 2 , … , r i , … , r n {\displaystyle r_{1},r_{2},\ldots ,r_{i},\ldots ,r_{n}} be such that a ≤ r i ≤ b {\displaystyle a\leq r_{i}\leq b} for finite a {\displaystyle a} and b {\displaystyle b} . To have confidence of at least δ {\displaystyle \delta } that | μ − m | < ϵ / 2 {\displaystyle |\mu -m|<\epsilon /2} , use a value for n {\displaystyle n} such that: n ≥ 2 ( b − a ) 2 ln ⁡ ( 2 / ( 1 − ( δ / 100 ) ) ) / ϵ 2 {\displaystyle n\geq 2(b-a)^{2}\ln(2/(1-(\delta /100)))/\epsilon ^{2}} For example, if δ = 99 % {\displaystyle \delta =99\%} , then n ≥ 2 ( b − a ) 2 ln ⁡ ( 2 / 0.01 ) / ϵ 2 ≈ 10.6 ( b − a ) 2 / ϵ 2 {\displaystyle n\geq 2(b-a)^{2}\ln(2/0.01)/\epsilon ^{2}\approx 10.6(b-a)^{2}/\epsilon ^{2}} . == Computational costs == Despite its conceptual and algorithmic simplicity, the computational cost associated with a Monte Carlo simulation can be staggeringly high. In general the method requires many samples to get a good approximation, which may incur an arbitrarily large total runtime if the processing time of a single sample is high. Although this is a severe limitation in very complex problems, the embarrassingly parallel nature of the algorithm allows this large cost to be reduced (perhaps to a feasible level) through parallel computing strategies in local processors, clusters, cloud computing, GPU, FPGA, etc. In financial and safety-critical applications, floating-point non-determinism across hardware platforms can compound these costs, as results may vary between runs or across different processors (x86, ARM, GPU), sometimes requiring redundant simulations or consensus mechanisms to verify numerical correctness. == History == Before the Monte Carlo method was developed, simulations tested a previously understood deterministic problem, and statistical sampling was used to estimate uncertainties in the simulations. Monte Carlo simulations invert this approach, solving deterministic problems using probabilistic metaheuristics (see simulated annealing). An early variant of the Monte Carlo method was devised to solve the Buffon's needle problem, in which π can be estimated by dropping needles on a floor made of parallel equidistant strips. In the 1930s, Enrico Fermi first experimented with the Monte Carlo method while studying neutron diffusion, but he did not publish this work. In the late 1940s, Stanisław Ulam invented the modern version of the Markov Chain Monte Carlo method while he was working on nuclear weapons projects at the Los Alamos National Laboratory. In 1946, nuclear weapons physicists at Los Alamos were investigating neutron diffusion in the core of a nuclear weapon. Despite having most of the necessary data, such as the average distance a neutron would travel in a substance before it collided with an atomic nucleus and how much energy the neutron was likely to give off following a collision, the Los Alamos physicists were unable to solve the problem using conventional, deterministic mathematical methods. Ulam proposed using random experiments. He recounts his inspiration as follows: The first thoughts and attempts I made to practice [the Monte Carlo Method] were suggested by a question which occurred to me in 1946 as I was convalescing from an illness and playing solitaires. The question was what are the chances that a Canfield solitaire laid out with 52 cards will come out successfully? After spending a lot of time trying to estimate them by pure combinatorial calculations, I wondered whether a more practical method than "abstract thinking" might not be to lay it out say one hundred times and simply observe and count the number of successful plays. This was already possible to envisage with the beginning of the new era of fast computers, and I immediately thought of problems of neutron diffusion and other questions of mathematical physics, and more generally how to change processes described by certain differential equations into an equivalent form interpretable as a succession of random operations. Later [in 1946], I described the idea to John von Neumann, and we began to plan actual calculations. Being secret, the work of von Neumann and Ulam required a code name. A colleague of von Neumann and Ulam, Nicholas Metropolis, suggested using the name Monte Carlo, which refers to the Monte Carlo Casino in Monaco where Ulam's uncle would borrow money from relatives to gamble. Monte Carlo methods were central to the simulations required for further postwar development of nuclear weapons, including the design of the H-bomb, though severely limited by the computational tools at the time. Von Neumann, Nicholas Metropolis and others programmed the ENIAC computer to perform the first fully automated Monte Carlo calculations, of a fission weapon core, in the spring of 1948. In the 1950s Monte Carlo methods were used at Los Alamos for the development of the hydrogen bomb, and became popularized in the fields of physics, physical chemistry, and operations research. The Rand Corporation and the U.S. Air Force were two of the major organizations responsible for funding and disseminating information on Monte Carlo methods during this time, and they began to find a wide application in many different fields. The theory of more sophisticated mean-field type particle Monte Carlo methods had certainly started by the mid-1960s, with the work of Henry P. McKean Jr. on Markov interpretations of a class of nonlinear parabolic partial differential equations arising in fluid mechanics. An earlier pioneering article by Theodore E. Harris and Herman Kahn, published in 1951, used mean-field genetic-type Monte Carlo methods for estimating particle transmission energies. Mean-field genetic type Monte Carlo methodologies are also used as heuristic natural search algorithms (a.k.a. metaheuristic) in evolutionary computing. The origins of these mean-field computational techniques can be traced to 1950 and 1954 with the work of Alan Turing on genetic type mutation-selection learning machines and the articles by Nils Aall Barricelli at the Institute for Advanced Study in Princeton, New Jersey. Quantum Monte Carlo, and more specifically diffusion Monte Carlo methods can also be interpreted as a mean-field particle Monte Carlo approximation of Feynman–Kac path integrals. The origins of Quantum Monte Carlo methods are often attributed to Enrico Fermi and Robert Richtmyer who developed in 1948 a mean-field particle interpretation of neutron-chain reactions, but the first heuristic-like and genetic type particle algorithm (a.k.a. Resampled or Reconfiguration Monte Carlo methods) for estimating ground state energies of quantum systems (in reduced matrix models) is due to Jack H. Hetherington in 1984. In molecular chemistry, the use of genetic heuristic-like particle methodologies (a.k.a. pruning and enrichment strategies) can be traced back to 1955 with the seminal work of Marshall N. Rosenbluth and Arianna W. Rosenbluth. The use of sequential Monte Carlo in advanced signal processing and Bayesian inference is more recent. It was in 1993, that Gordon et al., published in their seminal work the first application of a Monte Carlo resampling algorithm in Bayesian statistical inference. The authors named their algorithm 'the bootstrap filter', and demonstrated that compared to other filtering methods, their bootstrap algorithm does not require any assumption about that state-space or the noise of the system. Another pioneering article in this field was Genshiro Kitagawa's, on a related "Monte Carlo filter", and the ones by Pierre Del Moral and Himilcon Carvalho, Pierre Del Moral, André Monin and Gérard Salut on particle filters published in the mid-1990s. Particle filters were also developed in signal processing in 1989–1992 by P. Del

[Article truncated for benchmark context.]
