"""
Step 3: Combine Results from Step 1 and Step 2
Calculate fair comparison - no memory competition
"""

import json
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


def print_section(title: str):
    """Print formatted section."""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)


def main():
    """Combine results from both steps."""
    results_dir = Path("benchmarks/results")

    lms_path = results_dir / "lmstudio_only_results.json"
    poc_path = results_dir / "poc_only_results.json"

    # Load results
    with open(lms_path) as f:
        lms_results = json.load(f)
    with open(poc_path) as f:
        poc_results = json.load(f)

    # Combine
    combined = {
        "mlx_model": poc_results["mlx_model"],
        "lmstudio_model": lms_results["lmstudio_model"],
        "note": "Fair comparison - no memory competition, both warmed up, sequential runs",
        "scenarios": {
            "cold_start": {
                "this_poc": poc_results["scenarios"]["cold_start"],
                "lmstudio": lms_results["scenarios"]["cold_start"]
            },
            "session_resume": {
                "this_poc": poc_results["scenarios"]["session_resume"],
                "lmstudio": lms_results["scenarios"]["session_resume"]
            }
        }
    }

    # Calculate advantages
    poc_cold_time = combined["scenarios"]["cold_start"]["this_poc"]["total_time_sec"]
    lms_cold_time = combined["scenarios"]["cold_start"]["lmstudio"]["total_time_sec"]
    cold_diff = ((lms_cold_time - poc_cold_time) / lms_cold_time) * 100

    poc_resume_per = combined["scenarios"]["session_resume"]["this_poc"]["per_session_sec"]
    lms_resume_per = combined["scenarios"]["session_resume"]["lmstudio"]["avg_session_sec"]
    resume_advantage = ((lms_resume_per - poc_resume_per) / lms_resume_per) * 100

    combined["summary"] = {
        "cold_start_difference_percent": cold_diff,
        "session_resume_advantage_percent": resume_advantage
    }

    # Save combined results
    output_path = results_dir / "lmstudio_comparative_results.json"
    with open(output_path, 'w') as f:
        json.dump(combined, f, indent=2)

    # Print summary
    print_section("FINAL RESULTS - Fair Comparison")
    print("Both systems run sequentially, no memory competition")
    print("Both systems warmed up before measurement")
    print()
    print(f"Model: {combined['lmstudio_model']}")
    print()

    print("Cold Start:")
    print(f"  This POC:   {poc_cold_time:.2f}s")
    print(f"  LM Studio:  {lms_cold_time:.2f}s")
    if cold_diff > 0:
        print(f"  Result:     {abs(cold_diff):.1f}% FASTER (POC)")
    else:
        print(f"  Result:     {abs(cold_diff):.1f}% SLOWER (POC)")
    print()

    print("Session Resume (3-session average):")
    print(f"  This POC:   {poc_resume_per:.2f}s per session (cache load: 0.9-1.6ms)")
    print(f"  LM Studio:  {lms_resume_per:.2f}s per session (re-processes each time)")
    if resume_advantage > 0:
        print(f"  Result:     {resume_advantage:.1f}% FASTER with cache persistence (POC)")
    else:
        print(f"  Result:     {abs(resume_advantage):.1f}% SLOWER (POC)")
    print()

    # Key finding
    print("=" * 70)
    print("KEY FINDING:")
    print("=" * 70)
    poc_load_time = combined["scenarios"]["session_resume"]["this_poc"]["avg_load_time_sec"]
    speedup_factor = lms_resume_per / poc_load_time if poc_load_time > 0 else 0
    print(f"Cache load time: {poc_load_time*1000:.1f}ms")
    print(f"LM Studio re-process: {lms_resume_per:.2f}s")
    print(f"Speedup factor: {speedup_factor:.0f}x faster cache load")
    print("=" * 70)

    logger.info(f"\nâœ“ Combined results saved to: {output_path}")

    return combined


if __name__ == "__main__":
    main()
